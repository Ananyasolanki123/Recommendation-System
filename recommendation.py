# -*- coding: utf-8 -*-
"""Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wia344CjsJeI_-LlNuCiyMZ82RarWxqM
"""

import os
import zipfile
import struct
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from PIL import Image
import io
import io
import gradio as gr

import os
import zipfile
import struct
import numpy as np

# ========== Load MNIST ==========
def load_mnist_from_zip(zip_path, data_type='labels'):
    assert data_type in ['labels', 'images'], "data_type must be 'labels' or 'images'"
    extract_dir = os.path.splitext(zip_path)[0]
    os.makedirs(extract_dir, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_dir)
    extracted_files = os.listdir(extract_dir)
    idx_file = [f for f in extracted_files if f.endswith('.idx') or 'ubyte' in f][0]
    file_path = os.path.join(extract_dir, idx_file)
    if data_type == 'labels':
        with open(file_path, 'rb') as f:
            magic, num_items = struct.unpack(">II", f.read(8))
            data = np.frombuffer(f.read(), dtype=np.uint8)
    else:
        with open(file_path, 'rb') as f:
            magic, num_images, rows, cols = struct.unpack(">IIII", f.read(16))
            data = np.frombuffer(f.read(), dtype=np.uint8).reshape((num_images, rows, cols))
            data = data / 255.0
    return data

# Load MNIST and reduce size for quick training
zip_path ='/content/train-labels-idx1-ubyte (1).zip'
y_train = load_mnist_from_zip(zip_path, data_type='labels')[:1024]
zip_path = '/content/train-images-idx3-ubyte (1).zip'
x_train = load_mnist_from_zip(zip_path, data_type='images')[:1024]
zip_path = '/content/t10k-labels-idx1-ubyte.zip'
y_test = load_mnist_from_zip(zip_path, data_type='labels')[:256]
zip_path = '/content/t10k-images-idx3-ubyte (1).zip'
x_test = load_mnist_from_zip(zip_path, data_type='images')[:256]
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# ========== Utility Functions ==========
def one_hot_encode(y, num_classes):
    y = np.array(y).astype(int)
    one_hot = np.zeros((len(y), num_classes))
    one_hot[np.arange(len(y)), y] = 1
    return one_hot

def pad(image, pad_width=1):
    return np.pad(image, ((0, 0), (0, 0), (pad_width, pad_width), (pad_width, pad_width)), mode='constant')

# ========== Model Layers ==========
def initialize_filters(n_layers, input_channels=1, base_filters=4, filter_size=3):
    filters, biases = [], []
    in_channels = input_channels
    for i in range(n_layers):
        out_channels = base_filters * (2 ** i)
        layer_filters = np.random.randn(out_channels, in_channels, filter_size, filter_size) * np.sqrt(2. / (in_channels * filter_size * filter_size))
        layer_bias = np.zeros((out_channels, 1))
        filters.append(layer_filters)
        biases.append(layer_bias)
        in_channels = out_channels
    return filters, biases

def simple_conv2d(input, filters, bias, stride=1, padding=1):
    B, C_in, H, W = input.shape
    C_out, _, kH, kW = filters.shape
    input_padded = pad(input, padding)
    out_H = (H + 2 * padding - kH) // stride + 1
    out_W = (W + 2 * padding - kW) // stride + 1
    output = np.zeros((B, C_out, out_H, out_W))
    for b in range(B):
        for c_out in range(C_out):
            for i in range(out_H):
                for j in range(out_W):
                    h_start = i * stride
                    w_start = j * stride
                    region = input_padded[b, :, h_start:h_start + kH, w_start:w_start + kW]
                    conv = np.sum(region * filters[c_out])
                    output[b, c_out, i, j] = conv + bias[c_out, 0]
    return output


def relu(x):
    return np.maximum(0, x)

def max_pool2d(x, pool_size=2, stride=2):
    B, C, H, W = x.shape
    out_h = (H - pool_size) // stride + 1
    out_w = (W - pool_size) // stride + 1
    out = np.zeros((B, C, out_h, out_w))
    mask = np.zeros_like(x)
    for i in range(out_h):
        for j in range(out_w):
            h_start = i * stride
            h_end = h_start + pool_size
            w_start = j * stride
            w_end = w_start + pool_size
            window = x[:, :, h_start:h_end, w_start:w_end]
            max_val = np.max(window, axis=(2, 3), keepdims=True)
            out[:, :, i, j] = max_val.squeeze()
            mask_window = (window == max_val)
            mask[:, :, h_start:h_end, w_start:w_end] = mask_window
    return out, mask

def forward_pass_batch(x, filters, biases, n_layers, pool_size=2, stride=2):
    activations, masks, conv_inputs, conv_outs = [], [], [], []
    for i in range(n_layers):
        x_in = x.copy()
        conv_out = simple_conv2d(x_in, filters[i], biases[i])
        x_relu = relu(conv_out)
        x_pooled, mask = max_pool2d(x_relu, pool_size, stride)
        conv_inputs.append(x_in)
        conv_outs.append(conv_out)
        activations.append(x_pooled)
        masks.append(mask)
        x = x_pooled
    return x, activations, masks, conv_inputs, conv_outs


def flatten_batch(x):
    return x.reshape(x.shape[0], -1)


def dense(x, weights, bias):
    return np.dot(x, weights) + bias

def softmax(x):
    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=1, keepdims=True)
def cross_entropy_loss_batch(y_true, y_pred):
    return -np.mean(np.sum(y_true * np.log(y_pred + 1e-9), axis=1))

def backward_softmax_cross_entropy(y_pred, y_true):
    return (y_pred - y_true) / y_true.shape[0]
def max_pool2d_backward(dout, masks, pool_size=2, stride=2):
    B, C, H, W = masks.shape
    dx = np.zeros_like(masks)
    out_h = dout.shape[2]
    out_w = dout.shape[3]
    for i in range(out_h):
        for j in range(out_w):
            h_start = i * stride
            h_end = h_start + pool_size
            w_start = j * stride
            w_end = w_start + pool_size
            dx[:, :, h_start:h_end, w_start:w_end] += (
                masks[:, :, h_start:h_end, w_start:w_end] * dout[:, :, i, j][:, :, None, None]
            )
    return dx
def relu_backward(dout, x):
    return dout * (x > 0)
def simple_conv2d_backward(dout, input, filters, stride=1, padding=1):
    B, C_in, H, W = input.shape
    C_out, _, kH, kW = filters.shape
    _, _, out_H, out_W = dout.shape
    input_padded = pad(input, padding)
    dx_padded = np.zeros_like(input_padded)
    dW = np.zeros_like(filters)
    db = np.zeros(C_out)
    for b in range(B):
        for c_out in range(C_out):
            for i in range(out_H):
                for j in range(out_W):
                    h_start = i * stride
                    w_start = j * stride
                    h_end = h_start + kH
                    w_end = w_start + kW
                    region = input_padded[b, :, h_start:h_end, w_start:w_end]
                    dW[c_out] += dout[b, c_out, i, j] * region
                    dx_padded[b, :, h_start:h_end, w_start:w_end] += dout[b, c_out, i, j] * filters[c_out]
            db[c_out] += np.sum(dout[b, c_out])
    if padding > 0:
        dx = dx_padded[:, :, padding:-padding, padding:-padding]
    else:
        dx = dx_padded
    return dx, dW, db.reshape(C_out, 1)


# ========== Initialize Filters & FC Layer ==========
n_layers = int(input("Enter number of layers: "))
filters, biases = initialize_filters(n_layers)
x_sample = np.transpose(x_train[:1], (0, 3, 1, 2))
x_sample, _, _, _, _ = forward_pass_batch(x_sample, filters, biases, n_layers)
flattened_size = flatten_batch(x_sample).shape[1]
W_fc = np.random.randn(flattened_size, 10) * np.sqrt(2. / flattened_size)
b_fc = np.zeros((1, 10))

# ========== Training Loop ==========
learning_rate = 0.01
epochs = 10
batch_size = 32

for epoch in range(epochs):
    for i in range(0, len(x_train), batch_size):
        x_batch = x_train[i:i+batch_size]
        x_batch = np.transpose(x_batch, (0, 3, 1, 2))
        y_batch = y_train[i:i+batch_size]
        y_true = one_hot_encode(y_batch, 10)

        x, activations, masks, conv_inputs, conv_outs = forward_pass_batch(x_batch, filters, biases, n_layers)
        flat = flatten_batch(x)
        logits = dense(flat, W_fc, b_fc)
        probs = softmax(logits)
        loss = cross_entropy_loss_batch(y_true, probs)

        d_logits = backward_softmax_cross_entropy(probs, y_true)
        dW_fc = flat.T @ d_logits
        db_fc = np.sum(d_logits, axis=0, keepdims=True)
        d_flat = d_logits @ W_fc.T
        d_out = d_flat.reshape(x.shape)

        for l in reversed(range(n_layers)):
            d_pool = max_pool2d_backward(d_out, masks[l])
            d_relu = relu_backward(d_pool, conv_outs[l])
            x_in = x_batch if l == 0 else conv_inputs[l]
            dx, dW, db = simple_conv2d_backward(d_relu, x_in, filters[l])
            filters[l] -= learning_rate * dW
            biases[l] -= learning_rate * db
            d_out = dx

        W_fc -= learning_rate * dW_fc
        b_fc -= learning_rate * db_fc

        if i % (10 * batch_size) == 0:
            print(f"[Epoch {epoch+1}] Batch {i//batch_size}, Loss: {loss:.4f}")

    print(f"Epoch {epoch+1} Completed. Final Loss: {loss:.4f}")

# ========== Evaluation ==========
x_test_input = np.transpose(x_test, (0, 3, 1, 2))
x, _, _, _, _ = forward_pass_batch(x_test_input, filters, biases, n_layers)
flat_test = flatten_batch(x)
logits_test = dense(flat_test, W_fc, b_fc)
probs_test = softmax(logits_test)
y_pred = np.argmax(probs_test, axis=1)
accuracy = np.mean(y_pred == y_test)
print(f"\nâœ… Test Accuracy: {accuracy * 100:.2f}%")

from PIL import Image, ImageDraw

# Create a blank white image
img = Image.new('L', (28, 28), color=255)
draw = ImageDraw.Draw(img)

# Draw a dress-like shape (triangle skirt, top)
draw.polygon([(14, 5), (8, 18), (20, 18)], fill=150)  # skirt
draw.rectangle([12, 2, 16, 6], fill=100)  # top

img.save("/content/dress_28x28.png")
img.show()

x_train_input = np.transpose(x_train, (0, 3, 1, 2))
x_feats, _, _, _, _ = forward_pass_batch(x_train_input, filters, biases, n_layers)
x_train_flat_feats = flatten_batch(x_feats)

# ========== Recommendation Function ==========
def recommend_similar_image(input_image, x_train_set, x_train_feats):
    x_input = input_image.reshape(1, 28, 28, 1)
    x_input = np.transpose(x_input, (0, 3, 1, 2))
    x, _, _, _, _ = forward_pass_batch(x_input, filters, biases, n_layers)
    input_feat = flatten_batch(x)

    dot_products = np.dot(x_train_feats, input_feat.T).squeeze()
    norms = np.linalg.norm(x_train_feats, axis=1) * np.linalg.norm(input_feat)
    cosine_sim = dot_products / norms
    best_idx = np.argmax(cosine_sim)
    return best_idx, cosine_sim[best_idx]

# ========== Upload & Recommend from User Image ==========
uploaded = files.upload()

for filename in uploaded:
    img = Image.open(io.BytesIO(uploaded[filename])).convert('L').resize((28, 28))
    img_np = np.array(img) / 255.0
    input_img = img_np.reshape(28, 28)

    best_idx, score = recommend_similar_image(input_img, x_train, x_train_flat_feats)

    fig, axs = plt.subplots(1, 2)
    axs[0].imshow(input_img, cmap='gray')
    axs[0].set_title("ðŸ§‘ User Input")
    axs[1].imshow(x_train[best_idx].squeeze(), cmap='gray')
    axs[1].set_title(f"ðŸŽ¯ Match (Score: {score:.2f})")
    plt.show()